{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN5KB7A0GLTM",
        "outputId": "5c05dc27-f3fe-417c-915d-9b086b5d91c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.39.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.25.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: colorama in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\propserve\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0aqj3vxuGYhh"
      },
      "outputs": [],
      "source": [
        "#summarizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeMBobSfGXFy",
        "outputId": "140f772d-04bf-45ff-de99-33009944635f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\PropServe\\\\.cache\\\\huggingface\\\\hub\\\\models--facebook--bart-large-cnn\\\\snapshots\\\\37f520fa929c961707657b28798b30c003dd100b\\\\tokenizer.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the text you want to summarize: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Generate the summary\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mbart_summarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Print the original text and the summary\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, input_text)\n",
            "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mbart_summarize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbart_summarize\u001b[39m(text):\n\u001b[0;32m      4\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-cnn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mBartTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m BartForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      7\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer([text], max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\PropServe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2086\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2083\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2084\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pretrained(\n\u001b[0;32m   2087\u001b[0m     resolved_vocab_files,\n\u001b[0;32m   2088\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m   2089\u001b[0m     init_configuration,\n\u001b[0;32m   2090\u001b[0m     \u001b[38;5;241m*\u001b[39minit_inputs,\n\u001b[0;32m   2091\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   2092\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2093\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   2094\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m   2095\u001b[0m     _is_local\u001b[38;5;241m=\u001b[39mis_local,\n\u001b[0;32m   2096\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2097\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2098\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\PropServe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2305\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2301\u001b[0m \u001b[38;5;66;03m# allows converting a fast -> slow: add the `tokenizer.json`'s `\"added_tokens\"` to the slow tokenizer\u001b[39;00m\n\u001b[0;32m   2302\u001b[0m \u001b[38;5;66;03m# if `tokenizer_config.json` is `None`\u001b[39;00m\n\u001b[0;32m   2303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2304\u001b[0m     \u001b[38;5;66;03m# This is for slow so can be done before\u001b[39;00m\n\u001b[1;32m-> 2305\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m tokenizer_file_handle:\n\u001b[0;32m   2306\u001b[0m         tokenizer_file_handle \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(tokenizer_file_handle)\n\u001b[0;32m   2307\u001b[0m         added_tokens \u001b[38;5;241m=\u001b[39m tokenizer_file_handle\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madded_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\PropServe\\\\.cache\\\\huggingface\\\\hub\\\\models--facebook--bart-large-cnn\\\\snapshots\\\\37f520fa929c961707657b28798b30c003dd100b\\\\tokenizer.json'"
          ]
        }
      ],
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "def bart_summarize(text):\n",
        "    model_name = \"facebook/bart-large-cnn\"\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors=\"pt\")\n",
        "\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Get input from the user\n",
        "input_text = input(\"Enter the text you want to summarize: \")\n",
        "\n",
        "# Generate the summary\n",
        "summary = bart_summarize(input_text)\n",
        "\n",
        "# Print the original text and the summary\n",
        "print(\"Original Text:\\n\", input_text)\n",
        "print(\"\\nSummary:\\n\", summary)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
